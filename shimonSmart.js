// ğŸ“ shimonSmart.js â€“ ×ª×’×•×‘×” ×—×›××” ×‘×˜×œ×’×¨× ×¢× OpenAI v4, Firestore ×•Ö¾FIFO

const { OpenAI } = require("openai");
const { getScriptByUserId } = require("./data/fifoLines");
const db = require("./utils/firebase");

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const userCooldowns = new Map(); // userId -> timestamp

function estimateTokens(text) {
  return Math.ceil(text.length / 4);
}

function hasCooldown(userId) {
  const last = userCooldowns.get(userId) || 0;
  return (Date.now() - last) < 30 * 1000;
}

function updateCooldown(userId) {
  userCooldowns.set(userId, Date.now());
}

async function generateReply(userId, userText, name) {
  const profileLine = getScriptByUserId(userId)?.shimon || null;
  const contextLine = profileLine ? `××©×¤×˜ ××•×ª×× ×œ××©×ª××©: "${profileLine}"` : "";

  const isQuestion = userText.includes("?") || userText.startsWith("×œ××”") || userText.startsWith("××”");

  const prompt = isQuestion
    ? `××ª×” ×©××¢×•×Ÿ, ×‘×•×˜ ×’×™×™××™× ×’ ×™×©×¨××œ×™ ×¡×¨×§×¡×˜×™, ××‘×œ ×›×©×©×•××œ×™× ×©××œ×” â€“ ××ª×” ×¢×•× ×” ×‘×¨×¦×™× ×•×ª ×¢× ×¡×¨×§×–× ×—×›×.
××œ ×ª×–×œ×–×œ â€“ ×ª×¡×‘×™×¨ ×›××• ×—×‘×¨ ×•×ª×•×š ×›×“×™ ×ª×¦×—×§ ×¢×œ×™×”× ×›××• ×©××ª×” ×™×•×“×¢.
××•×ª×¨ ×œ×§×œ×œ, ××‘×œ ×ª×©××•×¨ ×¢×œ ×•×™×™×‘ ×©×œ ×¢×–×¨×”.
${contextLine}
×©××œ×” ×©× ×©××œ×”: ${userText}
×ª×Ÿ ×ª×©×•×‘×” ××œ××” ××š ×§×¦×¨×”, ×©× ×•× ×”, ×¢×‘×¨×™×ª.`

    : `××ª×” ×©××¢×•×Ÿ, ×‘×•×˜ ×’×™×™××™× ×’ ×™×©×¨××œ×™ ×¡×¨×§×¡×˜×™, ×’×¡, ×©× ×•×Ÿ ×•××¦×—×™×§ â€“ ××“×‘×¨ ×›××• ×—×‘×¨ ×‘Ö¾Discord.
×ª×’×™×‘ ×‘××©×¤×˜ ××—×“ ×‘×œ×‘×“. ××œ ×ª×ª×—× ×£. ×ª×§×œ×œ, ×ª×•×¨×™×“, ×ª×¦×—×§.
${contextLine}
××™×©×”×• ×›×ª×‘: ${userText}
×ª×Ÿ ×ª×’×•×‘×” ×©×œ ×¤×× ×¥' ×‘×¢×‘×¨×™×ª, ×”×›×™ ×™×©×™×¨×” ×©×™×© â€“ ×‘×œ×™ ×”×¡×‘×¨×™×.`

  const messages = [{ role: "user", content: prompt }];
  let reply, modelUsed;

  try {
    const res = await openai.chat.completions.create({
      model: "gpt-4o",
      messages,
      temperature: 0.95,
      max_tokens: 120
    });
    reply = res.choices[0].message.content.trim().replace(/^"|"$/g, "");
    modelUsed = "gpt-4o";
  } catch (err) {
    console.warn("âš ï¸ GPT-4o × ×›×©×œ:", err.message);
    try {
      const res = await openai.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages,
        temperature: 0.9,
        max_tokens: 100
      });
      reply = res.choices[0].message.content.trim().replace(/^"|"$/g, "");
      modelUsed = "gpt-3.5-turbo";
    } catch (err2) {
      console.error("âŒ ×’× GPT-3.5 × ×›×©×œ:", err2.message);
      return null;
    }
  }

  return {
    formatted: `\u200F<b>${name}</b> â€“ ${reply}`,
    plain: reply,
    model: modelUsed,
    tokens: estimateTokens(prompt + reply)
  };
}

async function logToFirestore(ctx, replyInfo, triggerText, triggerType) {
  try {
    await db.collection("messages").add({
      userId: ctx.from?.id,
      username: ctx.from?.username || null,
      chatId: ctx.chat?.id,
      text: ctx.message?.text || null,
      gptReply: replyInfo.plain,
      model: replyInfo.model,
      tokensUsed: replyInfo.tokens,
      triggeredBy: triggerText || null,
      triggerType: triggerType || null,
      timestamp: Date.now()
    });
  } catch (err) {
    console.error("âŒ Firestore log error:", err.message);
  }
}

// ğŸ“ ×¤×•× ×§×¦×™×” ×¨××©×™×ª
module.exports = async function handleSmartReply(ctx, triggerResult = { triggered: false }) {
  if (!ctx.message || !ctx.message.text || ctx.message.from?.is_bot) return false;

  const userId = ctx.from.id;
  const text = ctx.message.text;
  const name = ctx.from.first_name || "×—×‘×¨";

  if (hasCooldown(userId)) return false;

  const replyInfo = await generateReply(userId, text, name);
  if (!replyInfo) return false;

  await ctx.reply(replyInfo.formatted, { parse_mode: "HTML" });
  updateCooldown(userId);

  await logToFirestore(ctx, replyInfo, text, triggerResult?.type);

  return true;
};
