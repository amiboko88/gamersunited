// ğŸ“ ttsEngine.openai.js â€“ FIFO OPENAI TTS ENGINE PRO â€“ Buffer ×‘×œ×‘×“, ×‘×œ×™ textPreprocess

const axios = require('axios');
const admin = require('firebase-admin');
const { log } = require('../utils/logger');
const { getLineForUser, getScriptByUserId, fallbackScripts } = require('../data/fifoLines');

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

const VOICE_MAP = {
  shimon: 'nova',
  shirley: 'shimmer'
};

function getVoiceName(speaker = 'shimon') {
  return VOICE_MAP[speaker] || VOICE_MAP['shimon'];
}

async function checkOpenAIQuota(textLength) {
  return true;
}

async function synthesizeOpenAITTS(text, speaker = 'shimon') {
  const allowed = await checkOpenAIQuota(text.length);
  if (!allowed) {
    log(`ğŸ›‘ ×©××¢×•×Ÿ (OpenAI) ×”×©×ª×ª×§ â€“ ×¢×‘×¨× ×• ××’×‘×œ×”`);
    throw new Error("âŒ ×©××¢×•×Ÿ ×¢×‘×¨ ××’×‘×œ×” ×™×•××™×ª/×©×‘×•×¢×™×ª");
  }

  const voice = getVoiceName(speaker);
  const endpoint = "https://api.openai.com/v1/audio/speech";
  log(`ğŸ™ï¸ OpenAI TTS (${voice}) â€“ ${text.length} ×ª×•×•×™×`);

  const response = await axios.post(
    endpoint,
    {
      model: "tts-1",
      input: text,
      voice,
      response_format: "mp3"
    },
    {
      responseType: "arraybuffer",
      headers: {
        Authorization: `Bearer ${OPENAI_API_KEY}`,
        "Content-Type": "application/json"
      }
    }
  );

  if (!response.data || response.data.length < 1200) {
    throw new Error("ğŸ”‡ OpenAI ×œ× ×”×—×–×™×¨ ×§×•×œ ×ª×§×™×Ÿ");
  }

  await saveTTSAudit({
    text,
    voice,
    speaker,
    length: text.length,
    timestamp: new Date().toISOString()
  });

  return Buffer.from(response.data);
}

async function saveTTSAudit(data) {
  try {
    const db = admin.firestore();
    await db.collection('openaiTtsAudit').add(data);
  } catch (e) {
    log(`âš ï¸ ×œ× × ×©××¨ ×œÖ¾Firestore (audit): ${e.message}`);
  }
}

async function getShortTTSByProfile(member) {
  const userId = member.id;
  const displayName = member.displayName;
  let text = getLineForUser(userId, displayName);
  text = cleanTextForTTS(text);
  const voice = VOICE_MAP.shimon;
  log(`ğŸ—£ï¸ OpenAI TTS ××™×©×™ ×œÖ¾${displayName}: ${text}`);
  const mp3Buffer = await synthesizeOpenAITTS(text, 'shimon');
  return mp3Buffer;
}

// ğŸ§  ×ª×¡×¨×™×˜ ×¤×•×“×§××¡×˜ ×¢× ×œ×•×’×™×§×” ××ª×§×“××ª
async function getPodcastAudioOpenAI(displayNames = [], ids = [], joinTimestamps = {}) {
  const buffers = [];
  const participants = ids.map((uid, i) => ({
    id: uid,
    name: displayNames[i] || '×Ö´×©×Ö°×ªÖ¼Ö·×Ö¼Öµ×©×',
    joinedAt: joinTimestamps[uid] || 0,
    script: getScriptByUserId(uid)
  }));

  // ××™×•×Ÿ ×œ×¤×™ ×–××Ÿ ×”×¦×˜×¨×¤×•×ª
  participants.sort((a, b) => a.joinedAt - b.joinedAt);

  // ×ª×¡×¨×™×˜×™× ××•×ª×××™× ××• × ×¤×™×œ×” ×œ×’× ×¨×™
  const hasCustom = participants.some(p => p.script?.shimon || p.script?.shirley);
  const scriptsToUse = hasCustom
    ? participants.map(p => p.script || getRandomFallbackScript())
    : [getRandomFallbackScript()];

  for (const script of scriptsToUse) {
    if (script.shimon) buffers.push(await synthesizeOpenAITTS(cleanTextForTTS(script.shimon), 'shimon'));
    if (script.shirley) buffers.push(await synthesizeOpenAITTS(cleanTextForTTS(script.shirley), 'shirley'));
  }

  // ×× ×™×© ××™×©×”×• ×¢× ×¤×¨×•×¤×™×œ ××™×©×™ â€“ ×¤×× ×¥'
  if (participants.some(p => p.script)) {
    const punchScript = getRandomFallbackScript().punch;
    if (punchScript) {
      const randomSpeaker = Math.random() < 0.5 ? 'shimon' : 'shirley';
      buffers.push(await synthesizeOpenAITTS(cleanTextForTTS(punchScript), randomSpeaker));
    }
  }

  return Buffer.concat(buffers);
}

function getRandomFallbackScript() {
  return fallbackScripts[Math.floor(Math.random() * fallbackScripts.length)];
}

async function canUserUseTTS(userId, limit = 5) {
  return true;
}

// ğŸ§  ×¢×™×‘×•×“ ×˜×§×¡×˜ ××ª×§×“× ××•×ª×× ×œ×§×•×œ×•×ª ×¢×‘×¨×™×™× (OpenAI)
function cleanTextForTTS(text) {
  if (!text || typeof text !== 'string') return '';

  const pauseWords = ['×™××œ×œ×”', '×©××¢', '×˜×•×‘', '××—×™', '×›×¤×¨×”', '×”×œ×•', '× ×•', '×“×™'];
  const openingWords = ['×”×™×™', '××××œ×”', '×¤××§', '×‘×—×™×™××ª'];
  const replacements = [
    { pattern: /[!?]{2,}/g, replacement: '!' },
    { pattern: /\s{2,}/g, replacement: ' ' },
    { pattern: /\.{3,}/g, replacement: '...' },
    { pattern: /([×-×ª])\1{2,}/g, replacement: '$1' },
    { pattern: /(?:\n|\r|\r\n)/g, replacement: ' ' }
  ];

  let cleaned = text.trim();

  for (const { pattern, replacement } of replacements) {
    cleaned = cleaned.replace(pattern, replacement);
  }

  for (const word of pauseWords) {
    const regex = new RegExp(`\\b${word}\\b`, 'gi');
    cleaned = cleaned.replace(regex, match => {
      return cleaned.includes(`${match}...`) ? match : `${match}...`;
    });
  }

  for (const word of openingWords) {
    const regex = new RegExp(`\\b${word}(?![.,â€¦])\\b`, 'gi');
    cleaned = cleaned.replace(regex, `${word},`);
  }

  cleaned = cleaned
    .replace(/\.{4,}/g, '...')
    .replace(/,{2,}/g, ',')
    .replace(/\.\s+\./g, '.')
    .trim();

  return cleaned;
}

module.exports = {
  synthesizeOpenAITTS,
  getShortTTSByProfile,
  getPodcastAudioOpenAI,
  getVoiceName,
  canUserUseTTS
};
