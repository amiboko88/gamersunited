// ğŸ“ shimonSmart.js â€“ ×”×’× ×”, fallback ××œ×’× ×˜×™ ×•×“×™×œ×•×’ ×¢×œ Slash

const { OpenAI } = require("openai");
const { getScriptByUserId } = require("./data/fifoLines");
const db = require("./utils/firebase");

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const lastReplyPerUser = new Map();
const recentMessages = [];

function isUserSpammedRecently(userId) {
  const last = lastReplyPerUser.get(userId) || 0;
  return (Date.now() - last) < 5 * 1000;
}

function shouldSkipDueToActiveChat(ctx) {
  if (ctx.chat?.type === "private") return false;
  const now = Date.now();
  const updated = recentMessages.filter(e => now - e.ts < 20 * 1000);
  updated.push({ id: ctx.from?.id, ts: now });
  while (updated.length > 30) updated.shift();
  recentMessages.length = 0; recentMessages.push(...updated);
  const uniqueSenders = [...new Set(updated.map(e => e.id))];
  return uniqueSenders.length >= 6;
}

function estimateTokens(text) {
  return Math.ceil(text.length / 4);
}

function isOffensive(text) {
  const badWords = ["×–×™×Ÿ", "×—×¨×", "××¤×’×¨", "×‘×Ÿ ×–×•× ×”", "×›×•×¡", "fuck", "shit", "bitch"];
  return badWords.some(w => text.toLowerCase().includes(w));
}

function isTrigger(text) {
  const triggers = ["×©××¢×•×Ÿ", "bot", "×‘×•×˜", "shim"];
  return triggers.some(w => text.toLowerCase().includes(w));
}

function isNice(text) {
  const goodWords = ["×ª×•×“×”", "××œ×š", "×’×‘×¨", "respect"];
  return goodWords.some(w => text.toLowerCase().includes(w));
}

function isQuestion(text) {
  return text.endsWith("?") || ["××”", "×œ××”", "××™×š"].some(w => text.startsWith(w));
}

function cleanFallbackPrefix(text) {
  return text.replace(/fallback\s?#?\d+\s?[-â€“]\s?/i, "").trim();
}

function createPrompt({ userText, contextLine }) {
  const text = userText.trim();
  if (isOffensive(text)) {
    return `××©×ª××© ×§×™×œ×œ: "${text}"\n×©××¢×•×Ÿ â€“ ×ª×’×™×‘ ×‘×™×¨×™×“×” ×—×¨×™×¤×” ×•×¡×¨×§×¡×˜×™×ª. ${contextLine}`;
  }
  if (isTrigger(text)) {
    return `××™×©×”×• ×§×¨× ×œ×©××¢×•×Ÿ: "${text}"\n×ª×Ÿ ×ª×’×•×‘×” ×—×“×”, ××¦×—×™×§×” ×•××¢×˜ ×—×¦×•×¤×”. ${contextLine}`;
  }
  if (isNice(text)) {
    return `××©×ª××© ××—××™×: "${text}"\n×©××¢×•×Ÿ â€“ ×ª×—××™× ×‘×—×–×¨×”, ××‘×œ ×¢× ×˜×•×•×™×¡×˜ ×¦×™× ×™. ${contextLine}`;
  }
  if (isQuestion(text)) {
    return `×©××œ×” × ×©××œ×”: "${text}"\n×©××¢×•×Ÿ â€“ ×¢× ×” ×ª×©×•×‘×” ×¢× ×”×•××•×¨, ×¢×•×§×¦× ×•×ª ×•×˜×™×¤×” ×¢×•××§. ${contextLine}`;
  }
  return `×”×•×“×¢×” ×”×ª×§×‘×œ×”: "${text}"\n×©××¢×•×Ÿ â€“ ×ª×’×™×‘ ×‘×¡×¨×§×–× ×™×©×¨××œ×™, ×›×•×œ×œ ×™×¨×™×“×” ××¦×—×™×§×”. ${contextLine}`;
}

async function generateReply(userId, userText, name, triggerType) {
  const profileRaw = getScriptByUserId(userId)?.shimon || null;
  const profileLine = profileRaw ? cleanFallbackPrefix(profileRaw) : null;
  const contextLine = profileLine ? `××©×¤×˜ ××™×©×™: "${profileLine}"` : "";

  const prompt = createPrompt({ userText, contextLine });
  console.log("ğŸ“¤ Prompt:", prompt);

  const messages = [{ role: "user", content: prompt }];
  let reply, modelUsed;

  try {
    const res = await openai.chat.completions.create({
      model: "gpt-4o",
      messages,
      temperature: 0.93,
      max_tokens: 140
    });
    reply = res.choices[0]?.message?.content?.trim()?.replace(/^"|"$/g, "") || null;
    modelUsed = "gpt-4o";
  } catch (err) {
    console.warn("âš ï¸ GPT-4o × ×›×©×œ:", err.message);
    try {
      const res = await openai.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages,
        temperature: 0.9,
        max_tokens: 120
      });
      reply = res.choices[0]?.message?.content?.trim()?.replace(/^"|"$/g, "") || null;
      modelUsed = "gpt-3.5-turbo";
    } catch (err2) {
      console.error("âŒ ×’× GPT-3.5 × ×›×©×œ:", err2.message);
      reply = "×× ×™ ×›×¨×’×¢ ×¢×œ ×”×¤× ×™×. ×ª× ×¡×” ×©×•×‘ ×¢×•×“ ×¨×’×¢ â€“ ××• ×ª×“×‘×¨ ×™×¤×” ×™×•×ª×¨ ğŸ˜´";
      modelUsed = "fallback";
    }
  }

  return {
    formatted: `\u200F<b>${name}</b> â€“ ${reply}`,
    plain: reply,
    model: modelUsed,
    tokens: estimateTokens(prompt + reply)
  };
}

async function logToFirestore(ctx, replyInfo, triggerText, triggerType) {
  try {
    await db.collection("messages").add({
      userId: ctx.from?.id,
      username: ctx.from?.username || null,
      chatId: ctx.chat?.id,
      text: ctx.message?.text || null,
      gptReply: replyInfo.plain,
      model: replyInfo.model,
      tokensUsed: replyInfo.tokens,
      triggeredBy: triggerText || null,
      triggerType: triggerType || null,
      timestamp: Date.now()
    });
  } catch (err) {
    console.error("âŒ Firestore log error:", err.message);
  }
}

module.exports = async function handleSmartReply(ctx, triggerResult = { triggered: false }) {
  try {
    if (!ctx.message || !ctx.message.text || ctx.message.from?.is_bot) return false;

    //  ×“×™×œ×•×’ ×¢×œ ×¤×§×•×“×•×ª Slash (×›××• /start, /help)
  if  (ctx.message.text?.startsWith("/")) {
  console.log(" ×–×•×”×ª×” ×¤×§×•×“×ª Slash â€“ ×‘×•×˜ ×—×›× ××ª×¢×œ×");
  return false;
}

    const userId = ctx.from.id;
    const text = ctx.message.text;
    const name = ctx.from.first_name || "×—×‘×¨";

    // ğŸ› ï¸ ×œ×‘×“×™×§×•×ª: ×”×¡×¨ ×—×¡×™××•×ª ×–×× ×™×ª
    // if (isUserSpammedRecently(userId)) return false;
    // if (shouldSkipDueToActiveChat(ctx)) return false;

    const replyInfo = await generateReply(userId, text, name, triggerResult?.type);
    if (!replyInfo) {
      console.warn("âŒ ×œ× × ×•×¦×¨×” ×ª×©×•×‘×” â€“ replyInfo ×¨×™×§.");
      return false;
    }

    await ctx.reply(replyInfo.formatted, { parse_mode: "HTML" });
    lastReplyPerUser.set(userId, Date.now());
    await logToFirestore(ctx, replyInfo, text, triggerResult?.type);

    console.log(`ğŸŸ¢ ×ª×©×•×‘×” × ×©×œ×—×” (${replyInfo.model})`);
    return true;

  } catch (err) {
    console.error("âŒ ×©×’×™××” ×—×™×¦×•× ×™×ª ×‘Ö¾handleSmartReply:", err.message);
    try {
      await ctx.reply("âŒ ×©××¢×•×Ÿ ×”×¡×ª×‘×š ×¢× ×”×ª×’×•×‘×”. × ×¡×” ×©×•×‘.");
    } catch {}
    return false;
  }
};
