// ğŸ“ tts/ttsEngine.openai.js (×©× ×”×§×•×‘×¥ × ×©××¨ ttsEngine.elevenlabs.js ××¦×œ×š)
const { OpenAI } = require('openai');
const { log } = require('../utils/logger.js');
const { registerTTSUsage } = require('./ttsQuotaManager.eleven.js');

let openai;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY; 

if (OPENAI_API_KEY) {
    openai = new OpenAI({
        apiKey: OPENAI_API_KEY,
    });
    log('ğŸ”Š [OpenAI Engine] ×”×œ×§×•×— ×©×œ OpenAI ××•×ª×—×œ ×‘×”×¦×œ×—×”.');
} else {
    log('âš ï¸ [OpenAI Engine] ××©×ª× ×” ×”×¡×‘×™×‘×” OPENAI_API_KEY ×œ× × ××¦×. ×”×× ×•×¢ ××•×©×‘×ª.');
}

// --- ×”×’×“×¨×ª ×¤×¨×•×¤×™×œ×™× ×§×•×œ×™×™× ×©×œ OpenAI ---
const VOICE_CONFIG = {
    // --- ×§×•×œ×•×ª ×œ×¤×•×“×§××¡×˜ ---
    shimon: {
        model: 'gpt-4o-mini-tts',
        voice: 'ballad',
        instructions: 'Speak in a clear, neutral tone.' 
    },
    shirly: {
        model: 'gpt-4o-mini-tts',
        voice: 'coral',
        instructions: 'Speak in a clear, neutral tone.' 
    },
    
    // --- ×¤×¨×•×¤×™×œ×™× ×¡×˜×˜×™×™× ×œ×¤×§×•×“×ª /tts ---
    shimon_calm: {
        model: 'gpt-4o-mini-tts',
        voice: 'ballad',
        instructions: 'Speak in a very calm, slow, and relaxed tone.' 
    },
    shimon_energetic: {
        model: 'gpt-4o-mini-tts',
        voice: 'ballad',
        instructions: 'Speak in an energetic, excited, and fast-paced tone.' 
    },
};

const DEFAULT_PROFILE = VOICE_CONFIG.shimon;
// -----------------------------------------------------------------


/**
 * âœ… [×ª×™×§×•×Ÿ ×¡×•×¤×™] ×”×•×—×œ×¤×” ×œ×¤×•× ×§×¦×™×” ×”×§×œ××¡×™×ª (Node.js Stream) ×©×ª×•×××ª ×œ-OpenAI.
 * ×××™×¨ Stream ×œ-Buffer
 * @param {NodeJS.ReadableStream} stream 
 * @returns {Promise<Buffer>}
 */
function streamToBuffer(stream) {
    return new Promise((resolve, reject) => {
        const chunks = [];
        stream.on('data', (chunk) => chunks.push(chunk));
        stream.on('end', () => resolve(Buffer.concat(chunks)));
        stream.on('error', (error) => {
            log(`âŒ [streamToBuffer] ×©×’×™××” ×‘××™×¡×•×£ ×”-Stream: ${error.message}`);
            reject(error);
        });
    });
}

/**
 * ××™×™×¦×¨ ××•×“×™×• ×‘×•×“×“ ××˜×§×¡×˜.
 * @param {string} text - ×”×˜×§×¡×˜ ×œ×”×§×¨××”
 * @param {string} profileName - ×©× ×”×¤×¨×•×¤×™×œ (×œ××©×œ 'shimon_calm')
 * @param {import('discord.js').GuildMember} member - ×”××©×ª××© ×©×‘×™×§×©
 * @returns {Promise<Buffer|null>}
 */
async function synthesizeTTS(text, profileName = 'shimon_calm', member = null) {
    if (!openai) {
        log('âŒ [OpenAI Engine] × ×™×¡×™×•×Ÿ ×œ×”×©×ª××© ×‘×× ×•×¢ TTS ×›××©×¨ ×”×œ×§×•×— ××™× ×• ×××•×ª×—×œ.');
        return null;
    }
    
    const profile = VOICE_CONFIG[profileName] || DEFAULT_PROFILE;
    const cleanText = text.replace(/[*_~`]/g, '');
    
    try {
        log(`[OpenAI Engine] ××™×™×¦×¨ ××•×“×™×• ×¢×‘×•×¨: "${cleanText}" ×¢× ×¤×¨×•×¤×™×œ ${profileName} (×§×•×œ: ${profile.voice})`);
        
        const response = await openai.audio.speech.create({
            model: profile.model,
            voice: profile.voice,
            input: cleanText,
            response_format: 'mp3',
            instructions: profile.instructions 
        });
        
        // response.body ×”×•× NodeJS.ReadableStream, ×”×¤×•× ×§×¦×™×” ×”××ª×•×§× ×ª ×ª×¢×‘×•×“
        const audioBuffer = await streamToBuffer(response.body);

        const userId = member ? member.id : 'system';
        const username = member ? member.displayName : 'System';
        await registerTTSUsage(cleanText.length, userId, username, 'OpenAI', profileName);

        return audioBuffer;

    } catch (error) {
        log(`âŒ [OpenAI Engine] ×©×’×™××” ×§×¨×™×˜×™×ª ×‘×™×™×¦×•×¨ ×§×•×œ: ${error.message}`);
        log(error); 
        return null;
    }
}

/**
 * ××™×™×¦×¨ ×©×™×—×” ×©×œ××” (×¤×•×“×§××¡×˜) ××¡×§×¨×™×¤×˜.
 * @param {Array<{speaker: string, text: string}>} script 
 * @param {import('discord.js').GuildMember} member
 * @returns {Promise<Buffer[]>}
 */
async function synthesizeConversation(script, member) {
    if (!openai) {
        log(`âŒ [OpenAI Engine] × ×™×¡×™×•×Ÿ ×œ×”×©×ª××© ×‘×× ×•×¢ TTS (×©×™×—×”) ×›××©×¨ ×”×œ×§×•×— ××™× ×• ×××•×ª×—×œ.`);
        return [];
    }
    
    const audioBuffers = [];
    const userId = member.id;
    const username = member.displayName;

    for (const line of script) {
        if (!line.speaker || !line.text) continue;

        const cleanText = line.text.replace(/[*_~`]/g, '');
        const profileName = line.speaker.toLowerCase();
        const profile = VOICE_CONFIG[profileName] || DEFAULT_PROFILE;

        try {
            log(`[OpenAI Podcast] ××™×™×¦×¨ ×©×•×¨×”: [${profileName}] - "${cleanText}"`);

            const response = await openai.audio.speech.create({
                model: profile.model,
                voice: profile.voice,
                input: cleanText,
                response_format: 'mp3',
                instructions: profile.instructions 
            });
            
            // response.body ×”×•× NodeJS.ReadableStream, ×”×¤×•× ×§×¦×™×” ×”××ª×•×§× ×ª ×ª×¢×‘×•×“
            const audioBuffer = await streamToBuffer(response.body);
            audioBuffers.push(audioBuffer);

            await registerTTSUsage(cleanText.length, userId, username, 'OpenAI-Podcast', profileName);

        } catch (error) {
            log(`âŒ [OpenAI Podcast] ×©×’×™××” ×‘×™×™×¦×•×¨ ×©×•×¨×”: ${error.message}`);
            log(error); 
        }
    }
    
    log(`[OpenAI Podcast] ×™×¦×™×¨×ª ×”×©×™×—×” ×¢×‘×•×¨ ${username} ×”×¡×ª×™×™××”. ${audioBuffers.length} ×§×˜×¢×™ ××•×“×™×• × ×•×¦×¨×•.`);
    return audioBuffers;
}

module.exports = {
    synthesizeConversation,
    synthesizeTTS,
};