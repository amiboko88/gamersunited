// ðŸ“ handlers/voiceQueue.js â€“ × ×™×”×•×œ ×—×›× ×©×œ ×ª×•×¨ TTS, ×§×¨×¦×™×•×ª, ×¤×•×“×§××¡×˜×™× ×•×¢×•×“ (FIFO OpenAI + FFmpeg + Prism)

const { 
  joinVoiceChannel, 
  createAudioPlayer, 
  createAudioResource, 
  entersState, 
  AudioPlayerStatus, 
  VoiceConnectionStatus,
  StreamType
} = require('@discordjs/voice');

const { 
  getShortTTSByProfile, 
  getPodcastAudioOpenAI,
  canUserUseTTS
} = require('../tts/ttsEngine.openai');

const { shouldUseFallback } = require('../tts/ttsQuotaManager');

const { Readable } = require('stream');
const prism = require('prism-media');

const activeQueue = new Map();
const recentUsers = new Map();
const connectionLocks = new Set();

const TTS_TIMEOUT = 5000;
const CRITICAL_SPAM_WINDOW = 10_000;
const MULTI_JOIN_WINDOW = 6_000;
const BONUS_MIN_COUNT = 3;

// ×ž×ž×™×¨ Buffer ×œ-Stream (× ×“×¨×© ×œ-ffmpeg)
function bufferToStream(buffer) {
  return Readable.from(buffer);
}

// ðŸ† ×¤×•× ×§×¦×™×” ×—×›×ž×” â€“ ×ž×ž×™×¨×” mp3 ×œ-PCM (Discord ×“×•×¨×©) ×¢× ffmpeg+prism-media
async function playAudio(connection, audioBuffer) {
  // ×ž×ž×™×¨ mp3 ×ž×”-TTS ×œ-PCM RAW
  const prismStream = new prism.FFmpeg({
    args: [
      '-analyzeduration', '0',
      '-loglevel', '0',
      '-f', 'mp3',
      '-i', 'pipe:0',
      '-f', 's16le',
      '-ar', '48000',
      '-ac', '2',
      'pipe:1'
    ]
  });

  bufferToStream(audioBuffer).pipe(prismStream);

  const resource = createAudioResource(prismStream, { inputType: StreamType.Raw });
  const player = createAudioPlayer();
  connection.subscribe(player);
  player.play(resource);

  try {
    await entersState(player, AudioPlayerStatus.Idle, 30_000);
  } catch (err) {
    console.error('ðŸ›‘ ×”×©×ž×¢×” × ×›×©×œ×”:', err);
  }

  player.stop();
  connection.destroy();
}

// ×–×™×”×•×™ "×§×¨×¦×™×•×ª" â€“ ×ž×©×ª×ž×©×™× ×©×ž×¦×™×¤×™×/×ž×¦×™×§×™×
function isUserAnnoying(userId) {
  const now = Date.now();
  const timestamps = recentUsers.get(userId) || [];
  const newTimestamps = [...timestamps.filter(t => now - t < CRITICAL_SPAM_WINDOW), now];
  recentUsers.set(userId, newTimestamps);
  return newTimestamps.length >= 3;
}

/**
 * ×ª×•×¨ TTS ×—×›× â€“ ×ª×•×ž×š ×‘×”×©×ž×¢×” ×§×‘×•×¦×ª×™×ª (×¤×•×“×§××¡×˜) ×•×‘×•×“×“×ª, ×›×•×œ×œ ×§×¨×¦×™×•×ª, ×‘×•× ×•×¡×™×, Fallback
 * @param {GuildMember} member 
 * @param {VoiceChannel} channel 
 */
async function processUserSmart(member, channel) {
  const userId = member.id;
  const guildId = channel.guild.id;
  const key = `${guildId}-${channel.id}`;

  if (!activeQueue.has(key)) activeQueue.set(key, []);
  const queue = activeQueue.get(key);

  queue.push({ member, timestamp: Date.now() });

  // ×× ×›×‘×¨ ×™×© ×”×©×ž×¢×” ×¤×¢×™×œ×” â€“ × ×ž×ª×™×Ÿ
  if (connectionLocks.has(key)) return;
  connectionLocks.add(key);

  while (queue.length > 0) {
    const { member: nextMember, timestamp } = queue.shift();

    // ×”×’× ×” â€“ ×§×¨×¦×™×•×ª
    if (isUserAnnoying(nextMember.id)) {
      console.log(`ðŸ¤¬ ${nextMember.displayName} ×ž×ª× ×”×’ ×›×ž×• ×§×¨×¦×™×™×”`);
      continue;
    }

    // ×‘×§×¨×ª ×©×™×ž×•×© â€“ quota ××™×©×™ (××¤×©×¨ ×œ×›×‘×•×ª ×¢"×™ ×”×’×‘×œ×ª limit ×’×‘×•×” ×ž××•×“)
    if (!(await canUserUseTTS(nextMember.id, 10))) { // ×‘×¨×™×¨×ª ×ž×—×“×œ: 10 ×”×©×ž×¢×•×ª ×œ×ž×©×ª×ž×© ×‘×™×•×
      console.log(`â›”ï¸ ${nextMember.displayName} ×—×¨×’ ×ž×”×ž×’×‘×œ×” ×”×™×•×ž×™×ª ×”××™×©×™×ª`);
      continue;
    }

    // ×–×™×”×•×™ ×”×ª×—×‘×¨×•×ª ×§×‘×•×¦×ª×™×ª (×¤×•×“×§××¡×˜) â€“ ×ª×•×š MULTI_JOIN_WINDOW
    const joinedClose = queue.some(item =>
      item.member.id !== nextMember.id &&
      Math.abs(item.timestamp - timestamp) <= MULTI_JOIN_WINDOW
    );

    const usePodcast = joinedClose;
    const useFallback = await shouldUseFallback();
    let audioBuffer;

    try {
      if (usePodcast) {
        // ×¤×•×“×§××¡×˜ ×§×‘×•×¦×ª×™ (×¨×™×‘×•×™ ×ž×¦×˜×¨×¤×™×) â€“ ×§×•×œ×•×ª FIFO, ×ž×©×¤×˜×™× ×ž×•×ª××ž×™×
        const displayNames = queue.map(item => item.member.displayName);
        const ids = queue.map(item => item.member.id);
        audioBuffer = await getPodcastAudioOpenAI(displayNames, ids);
      } else {
        // TTS ××™×©×™ â€“ ×œ×¤×™ ×¤×¨×•×¤×™×œ ×”×ž×©×ª×ž×© (×›×•×œ×œ Fallback)
        audioBuffer = await getShortTTSByProfile(nextMember, useFallback);
      }
    } catch (err) {
      console.error(`TTS error:`, err);
      continue;
    }

    // ×™×¦×™×¨×ª ×•×”×¤×¢×œ×ª ×—×™×‘×•×¨ ×§×•×œ×™
    const connection = joinVoiceChannel({
      channelId: channel.id,
      guildId: channel.guild.id,
      adapterCreator: channel.guild.voiceAdapterCreator
    });

    try {
      await entersState(connection, VoiceConnectionStatus.Ready, 15_000);
      await playAudio(connection, audioBuffer);
    } catch (err) {
      console.error('ðŸ”Œ ×©×’×™××” ×‘×”×©×ž×¢×”:', err);
    }

    await wait(TTS_TIMEOUT);
  }

  connectionLocks.delete(key);
}

function wait(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

module.exports = {
  processUserSmart
};
