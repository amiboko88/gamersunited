// ğŸ“ tts/ttsEngine.elevenlabs.js
const fs = require('fs');
const path = require('path');
const { OpenAI } = require('openai');
const { log } = require('../utils/logger'); 
const { registerTTSUsage } = require('./ttsQuotaManager.eleven.js');

const openai = new OpenAI({ 
    apiKey: process.env.OPENAI_API_KEY 
});

// --- ğŸ­ ×××’×¨ ×§×•×œ×•×ª ××’×•×•×Ÿ (HD) ğŸ­ ---
// ×”×’×“×¨×ª×™ ×§×‘×•×¢×™× ×›×“×™ ×©×™×”×™×” ×§×œ ×œ×©× ×•×ª ×‘×¢×ª×™×“
const VOICE_POOLS = {
    shimon: ['ash', 'onyx', 'echo'],      // ×’×‘×¨×™×™× ×¨×¦×™× ×™×™×
    shirly: ['coral', 'nova', 'shimmer'], // × ×©×™×™× ××’×•×•× ×™×
    narrator: ['alloy', 'fable']          // × ×™×˜×¨×œ×™
};

function getRandomVoice(character) {
    const pool = VOICE_POOLS[character] || VOICE_POOLS.narrator;
    return pool[Math.floor(Math.random() * pool.length)];
}

/**
 * ×¤×•× ×§×¦×™×™×ª ×¢×–×¨ ×œ×™×™×¦×•×¨ ×§×•×‘×¥ ××•×“×™×• ×¤×™×–×™
 * (× ×—×•×¥ ×›×™ ××¢×¨×›×ª ×”-Queue ×©×œ×š ×¢×•×‘×“×ª ×¢× × ×ª×™×‘×™ ×§×‘×¦×™×)
 */
async function generateAudioFile(text, voice, fileName) {
    try {
        // ×‘×§×©×” ×œ-OpenAI
        const mp3 = await openai.audio.speech.create({
            model: "tts-1-hd", // ××™×›×•×ª ×’×‘×•×”×”
            voice: voice,
            input: text,
            speed: 1.0
        });

        const buffer = Buffer.from(await mp3.arrayBuffer());
        
        // ×™×¦×™×¨×ª ×”×ª×™×§×™×™×” ×× ×œ× ×§×™×™××ª
        const outputDir = path.join(__dirname, '../temp_tts');
        if (!fs.existsSync(outputDir)) {
            fs.mkdirSync(outputDir, { recursive: true });
        }

        const filePath = path.join(outputDir, fileName);
        fs.writeFileSync(filePath, buffer);
        
        return filePath;

    } catch (error) {
        log(`âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×§×•×‘×¥ ××•×“×™×• (${fileName}): ${error.message}`);
        return null;
    }
}

/**
 * ××¤×™×§ ×©×™×—×” ×©×œ××” (×¤×•×“×§××¡×˜)
 * ××§×‘×œ ××¢×¨×š ×©×œ ×©×•×¨×•×ª: [{ speaker: 'shimon', text: '...' }, ...]
 */
async function synthesizeConversation(script, member) {
    if (!process.env.OPENAI_API_KEY) {
        log("âŒ ×©×’×™××”: ×—×¡×¨ OPENAI_API_KEY ×‘×§×•×‘×¥ ×”×¡×‘×™×‘×”.");
        return [];
    }

    const audioFiles = [];

    // ×‘×—×™×¨×ª ×§×•×œ×•×ª ×§×‘×•×¢×™× ×œ×›×œ ×”×©×™×—×” ×”×–×• (×›×“×™ ×œ×©××•×¨ ×¢×œ ×¨×¦×£ ×•×¢×§×‘×™×•×ª ×‘×©×™×—×” ××—×ª)
    const sessionVoices = {
        shimon: getRandomVoice('shimon'),
        shirly: getRandomVoice('shirly'),
        narrator: getRandomVoice('narrator')
    };

    log(`[Podcast Init] ğŸ™ï¸ ×§×•×œ×•×ª ×œ×©×™×—×”: ×©××¢×•×Ÿ (${sessionVoices.shimon}) | ×©×™×¨×œ×™ (${sessionVoices.shirly})`);

    let index = 0;
    for (const line of script) {
        if (!line.speaker || !line.text) continue;

        index++;
        const speakerKey = line.speaker.toLowerCase();
        let selectedVoice = sessionVoices.narrator;

        // ×–×™×”×•×™ ×”×“×•×‘×¨
        if (speakerKey.includes('shimon') || speakerKey.includes('×©××¢×•×Ÿ')) {
            selectedVoice = sessionVoices.shimon;
        } else if (speakerKey.includes('shirly') || speakerKey.includes('×©×™×¨×œ×™')) {
            selectedVoice = sessionVoices.shirly;
        }

        const fileName = `line_${index}_${line.speaker}_${Date.now()}.mp3`;
        const filePath = await generateAudioFile(line.text, selectedVoice, fileName);

        if (filePath) {
            audioFiles.push(filePath);
            
            // âœ… ×“×™×•×•×— ×¦×¨×™×›×” ×œ××¢×¨×›×ª ×”××›×¡×•×ª ×”×—×“×©×”
            // ××–×”×” ××ª ×”××©×ª××© ×©×™×–× ××ª ×”×¤×•×“×§××¡×˜ (member)
            if (member && member.user) {
                await registerTTSUsage(
                    line.text.length, 
                    member.user.id, 
                    member.user.username, 
                    'openai-hd', 
                    selectedVoice
                );
            }
        }
    }

    return audioFiles; // ××—×–×™×¨ ××¢×¨×š ×©×œ × ×ª×™×‘×™× ×œ×§×‘×¦×™× ×©× ×•×¦×¨×•
}

// ×¤×•× ×§×¦×™×” ×’× ×¨×™×ª ×œ×™×¦×™×¨×ª ××©×¤×˜ ×‘×•×“×“ (×œ×©×™××•×© ×‘×¨×•×¡×˜×™× ×‘×•×“×“×™× ×•×›×•')
async function synthesizeTTS(text, voiceProfile = 'shimon') {
    const voice = getRandomVoice(voiceProfile);
    const mp3 = await openai.audio.speech.create({
        model: "tts-1-hd",
        voice: voice,
        input: text,
    });
    return Buffer.from(await mp3.arrayBuffer());
}

module.exports = { synthesizeConversation, synthesizeTTS };