const fs = require('fs');
const path = require('path');
const { OpenAI } = require('openai');
const axios = require('axios');
const { log } = require('../../utils/logger');

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

class VoiceManager {

    constructor() {
        // ×ª××™×›×” ×‘×©××•×ª ×©×”××©×ª××© ×”×’×“×™×¨ (ELEVEN_*) ×‘×œ×‘×“ (×œ×‘×§×©×ª ×”××©×ª××©)
        this.elevenLabsKey = process.env.ELEVEN_API_KEY;
        this.voiceId = process.env.ELEVEN_VOICE_ID || 'txHtK15K5KtX959ZtpRa';

        // ğŸ”´ Safeguard: ×× ×”×•×’×“×¨ ×‘×˜×¢×•×ª ×”-ID ×”×©×’×•×™ (n4en...), × ×—×œ×™×£ ××•×ª×• ×‘×›×•×— ×œ× ×›×•×Ÿ
        if (this.voiceId === 'n4enD9rhtsV2P8yfZk9g') {
            log('âš ï¸ [Voice] ×–×•×”×” Voice ID ×©×’×•×™ (× ×œ×§×— ××”-Env). ××‘×¦×¢ ×”×—×œ×¤×” ××•×˜×•××˜×™×ª ×œ-ID ×”× ×›×•×Ÿ.');
            this.voiceId = 'txHtK15K5KtX959ZtpRa';
        }
    }

    /**
     * ×××™×¨ ×§×•×‘×¥ ×©××¢ ×œ×˜×§×¡×˜ (Speech to Text) ×‘×××¦×¢×•×ª Whisper
     * @param {string} filePath × ×ª×™×‘ ×œ×§×•×‘×¥ ×”×©××¢ ×”××§×•××™
     */
    async transcribe(filePath) {
        try {
            log(`ğŸ™ï¸ [Voice] Transcribing file: ${filePath}`);
            const response = await openai.audio.transcriptions.create({
                file: fs.createReadStream(filePath),
                model: "whisper-1",
                language: "he" // ×× ×¡×” ×œ××§×“ ×œ×¢×‘×¨×™×ª
            });
            return response.text;
        } catch (error) {
            log(`âŒ [Voice] Transcription Failed: ${error.message}`);
            return null;
        }
    }

    /**
     * ×××™×¨ ×˜×§×¡×˜ ×œ×“×™×‘×•×¨ (Text to Speech) ×‘×××¦×¢×•×ª ElevenLabs
     * @param {string} text ×”×˜×§×¡×˜ ×œ×”×§×¨××”
     * @returns {Promise<Buffer>} ×”-Buffer ×©×œ ×§×•×‘×¥ ×”×©××¢
     */
    async speak(text, voiceIdOverride = null) {
        if (!this.elevenLabsKey) {
            log('âŒ [Voice] Missing ELEVEN_API_KEY');
            return null;
        }

        // × ×™×§×•×™ ×”×˜×§×¡×˜ ××ª×’×™×•×ª ×¤× ×™××™×•×ª
        const cleanText = text.replace('[VOICE]', '').trim();
        if (!cleanText) return null;

        const targetVoiceId = voiceIdOverride || this.voiceId;

        try {
            log(`ğŸ—£ï¸ [Voice] Generating audio for: "${cleanText.substring(0, 20)}..." (Voice: ${targetVoiceId})`);

            const response = await axios({
                method: 'POST',
                url: `https://api.elevenlabs.io/v1/text-to-speech/${targetVoiceId}`,
                headers: {
                    'Accept': 'audio/mpeg',
                    'xi-api-key': this.elevenLabsKey,
                    'Content-Type': 'application/json'
                },
                data: {
                    text: cleanText,
                    model_id: "eleven_multilingual_v3", // V3 (2026 Standard)
                    voice_settings: {
                        stability: 0.5,
                        similarity_boost: 0.75
                    }
                },
                responseType: 'arraybuffer'
            });

            return Buffer.from(response.data);

        } catch (error) {
            log(`âŒ [Voice] TTS Failed: ${error.message}`);
            return null;
        }
    }
}

module.exports = new VoiceManager();
