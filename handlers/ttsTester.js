// ğŸ“ handlers/ttsTester.js
// âœ… ×’×¨×¡×” ×¡×•×¤×™×ª - ××•×ª×××ª ×‘××•×¤×Ÿ ××œ× ×œ×§×¨×™××” ×-voiceHandler.js

const { joinVoiceChannel, createAudioPlayer, createAudioResource, AudioPlayerStatus, VoiceConnectionStatus, entersState } = require('@discordjs/voice');
const { log } = require('../utils/logger');
const { Readable } = require('stream');
const OpenAI = require('openai');
const { TextToSpeechClient } = require('@google-cloud/text-to-speech');

// --- ×”×’×“×¨×•×ª ×•××©×ª× ×™ ×¡×‘×™×‘×” ---
const TEST_CHANNEL_ID = '1396779274173943828';
const SHIMON_VOICE_OPENAI = 'onyx';
const SHIMON_VOICE_GOOGLE = 'he-IL-Wavenet-C';

// --- ××ª×—×•×œ ×”×œ×§×•×—×•×ª ×©×œ ×©×™×¨×•×ª×™ ×”-API ---
const openai = new OpenAI(); 
let googleTtsClient;
const googleCredentialsJson = process.env.GOOGLE_CREDENTIALS_JSON;

if (googleCredentialsJson) {
    try {
        const credentials = JSON.parse(googleCredentialsJson);
        googleTtsClient = new TextToSpeechClient({ credentials });
    } catch (error) {
        log.error('[TTS_TESTER] âŒ Failed to parse GOOGLE_CREDENTIALS_JSON.', error);
        googleTtsClient = null;
    }
}

// --- ××©×ª× ×™ ×¢×–×¨ ---
let nextEngine = 'openai';
let isTestRunning = false;

// --- ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ ×œ×™×™×¦×•×¨ ×§×•×œ ---
async function generateOpenAIVoice(text) {
    const mp3 = await openai.audio.speech.create({ model: 'tts-1-hd', voice: SHIMON_VOICE_OPENAI, input: text });
    return Buffer.from(await mp3.arrayBuffer());
}

async function generateGoogleVoice(text) {
    if (!googleTtsClient) throw new Error('Google TTS client is not initialized.');
    const [response] = await googleTtsClient.synthesizeSpeech({
        input: { text }, voice: { languageCode: 'he-IL', name: SHIMON_VOICE_GOOGLE }, audioConfig: { audioEncoding: 'MP3' },
    });
    return response.audioContent;
}


// --- âœ¨ ×”×¤×•× ×§×¦×™×” ×”××¨×›×–×™×ª ×©×”-voiceHandler ×§×•×¨× ×œ×” ---
async function runTTSTest(member) {
    if (isTestRunning) {
        log('[TTS_TESTER] ×‘×“×™×§×” ×›×‘×¨ ×¨×¦×”, ××“×œ×’ ×¢×œ ×”×¤×¢×œ×” ×›×¤×•×œ×”.');
        return;
    }

    isTestRunning = true;
    log(`[TTS_TESTER] â¡ï¸  ×”×ª×—×œ×ª ×‘×“×™×§×ª TTS ×¢×‘×•×¨ ${member.displayName}`);
    
    let engineToUse = nextEngine;
    nextEngine = (engineToUse === 'openai') ? 'google' : 'openai';
    
    if (engineToUse === 'google' && !googleTtsClient) {
        log('[TTS_TESTER] âš ï¸ ×× ×•×¢ ×’×•×’×œ ×œ× ×–××™×Ÿ, ×¢×•×‘×¨ ×œ-OpenAI.');
        engineToUse = 'openai'; 
        nextEngine = 'google';
    }

    log(`[TTS_TESTER] × ×‘×—×¨ ×× ×•×¢: [${engineToUse.toUpperCase()}]`);

    let connection;
    try {
        connection = joinVoiceChannel({
            channelId: member.voice.channelId, guildId: member.guild.id, adapterCreator: member.guild.voiceAdapterCreator,
        });

        const textToSpeak = `×”×™×™ ${member.displayName}, ×©××¢×•×Ÿ ×‘×•×“×§ ××ª ×× ×•×¢ ×”×§×•×œ ×©×œ ${engineToUse}.`;
        const audioBuffer = await (engineToUse === 'google' ? generateGoogleVoice(textToSpeak) : generateOpenAIVoice(textToSpeak));
        
        const player = createAudioPlayer();
        const resource = createAudioResource(Readable.from(audioBuffer));
        connection.subscribe(player);
        player.play(resource);

        await entersState(player, AudioPlayerStatus.Playing, 5_000);
        log('[TTS_TESTER] âœ… ×”× ×™×’×•×Ÿ ×”×ª×—×™×œ.');

        await entersState(player, AudioPlayerStatus.Idle, 30_000);
        log('[TTS_TESTER] âœ… ×”× ×™×’×•×Ÿ ×”×¡×ª×™×™×.');
        
    } catch (error) {
        log.error(`[TTS_TESTER] âŒ ×©×’×™××” ×§×¨×™×˜×™×ª ×‘×ª×”×œ×™×š ×”×‘×“×™×§×”:`, error);
    } finally {
        if (connection && connection.state.status !== VoiceConnectionStatus.Destroyed) {
            connection.destroy();
        }
        isTestRunning = false;
        log('[TTS_TESTER] â¹ï¸  ×ª×”×œ×™×š ×”×‘×“×™×§×” ×”×¡×ª×™×™×.');
    }
}

// --- ×™×™×¦×•× ×”××•×“×•×œ ---
module.exports = {
    runTTSTest,
    TEST_CHANNEL_ID
};