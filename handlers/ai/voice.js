const fs = require('fs');
const path = require('path');
const { OpenAI } = require('openai');
const axios = require('axios');
const { log } = require('../../utils/logger');

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

class VoiceManager {

    constructor() {
        // ×ª××™×›×” ×‘×©××•×ª ×©×”××©×ª××© ×”×’×“×™×¨ (ELEVEN_*) ×‘×œ×‘×“ (×œ×‘×§×©×ª ×”××©×ª××©)
        this.elevenLabsKey = process.env.ELEVEN_API_KEY;
        this.voiceId = 'txHtK15K5KtX959ZtpRa';
    }

    /**
     * ×××™×¨ ×§×•×‘×¥ ×©××¢ ×œ×˜×§×¡×˜ (Speech to Text) ×‘×××¦×¢×•×ª Whisper
     * @param {string} filePath × ×ª×™×‘ ×œ×§×•×‘×¥ ×”×©××¢ ×”××§×•××™
     */
    async transcribe(filePath) {
        try {
            log(`ğŸ™ï¸ [Voice] Transcribing file: ${filePath}`);
            const response = await openai.audio.transcriptions.create({
                file: fs.createReadStream(filePath),
                model: "whisper-1",
                language: "he" // ×× ×¡×” ×œ××§×“ ×œ×¢×‘×¨×™×ª
            });
            return response.text;
        } catch (error) {
            log(`âŒ [Voice] Transcription Failed: ${error.message}`);
            return null;
        }
    }

    /**
     * ×××™×¨ ×˜×§×¡×˜ ×œ×“×™×‘×•×¨ (Text to Speech) ×‘×××¦×¢×•×ª ElevenLabs
     * @param {string} text ×”×˜×§×¡×˜ ×œ×”×§×¨××”
     * @returns {Promise<Buffer>} ×”-Buffer ×©×œ ×§×•×‘×¥ ×”×©××¢
     */
    async speak(text, options = {}) {
        if (!this.elevenLabsKey) {
            log('âŒ [Voice] Missing ELEVEN_API_KEY');
            return null;
        }

        const cleanText = text.replace(/[*_~`]/g, '').replace('[VOICE]', '').trim();
        if (!cleanText) return null;

        // Determine Configuration
        // Priority: Options -> Default Class Property -> Hardcoded Fallback
        const voiceId = options.voiceId || this.voiceId;
        const modelId = options.modelId || "eleven_v3"; // âœ… Enforced V3 for Hebrew stability

        // Settings: Allow per-call overrides, otherwise use defaults
        const settings = {
            stability: options.stability !== undefined ? options.stability : 0.5, // V3 Optimized for Hebrew: 0.5
            similarity_boost: options.similarityBoost || 0.8,
            style: options.style || 0.5, // V3 supports style
            use_speaker_boost: options.useSpeakerBoost !== undefined ? options.useSpeakerBoost : true
        };

        try {
            log(`ğŸ—£ï¸ [Voice] Generating audio (ElevenLabs)...
            - Text: "${cleanText.substring(0, 20)}..."
            - Voice: ${voiceId}
            - Model: ${modelId}`);

            const response = await axios({
                method: 'POST',
                url: `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`,
                headers: {
                    'Accept': 'audio/mpeg',
                    'xi-api-key': this.elevenLabsKey,
                    'Content-Type': 'application/json'
                },
                data: {
                    text: cleanText,
                    model_id: modelId,
                    voice_settings: settings
                },
                responseType: 'arraybuffer'
            });

            return Buffer.from(response.data);

        } catch (error) {
            if (error.response && error.response.data) {
                const errMsg = Buffer.isBuffer(error.response.data)
                    ? error.response.data.toString()
                    : JSON.stringify(error.response.data);
                log(`âŒ [Voice] TTS Critical Failure (${voiceId}): ${errMsg}`);
                return null;
            } else {
                log(`âŒ [Voice] TTS Failed: ${error.message}`);
                return null;
            }
        }
    }
}

module.exports = new VoiceManager();
